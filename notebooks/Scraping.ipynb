{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Crear columnas nuevas vacías para la información que scrapeo\n",
    "df_steam_games['publisher_scraped'] = None\n",
    "df_steam_games['genres_scraped'] = None\n",
    "df_steam_games['app_name_scraped'] = None\n",
    "# df_steam_games['title'] = None\n",
    "df_steam_games['release_date_scraped'] = None\n",
    "# df_steam_games['tags'] = None\n",
    "# df_steam_games['reviews_url'] = None\n",
    "# df_steam_games['specs'] = None\n",
    "df_steam_games['price_scraped'] = None\n",
    "# df_steam_games['early_access'] = None\n",
    "# df_steam_games['developer'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Creo una función de scrapeo pero sólo de las columnas que voy a necesitar para las funciones\n",
    "def scrape_steam_game_info(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve data for URL: {url}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Guardar el contenido de soup en un archivo .txt\n",
    "    with open(\"soup_content.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(soup.prettify())\n",
    "    \n",
    "  #  print (soup)\n",
    "    try:\n",
    "        # Extracting information\n",
    "        app_name = soup.find('div', class_='apphub_AppName').text.strip() if soup.find('div', class_='apphub_AppName') else None\n",
    "        # title = app_name  # You can use app_name as title since they are the same\n",
    "        grid_content = soup.find('div', class_='grid_content')\n",
    "        if grid_content:\n",
    "            publisher_link = grid_content.find('a')\n",
    "            if publisher_link:\n",
    "                publisher = publisher_link.text.strip()\n",
    "        genres = [genre.text.strip() for genre in soup.find_all('a', class_='app_tag')]\n",
    "        release_date = soup.find('div', class_='date').text.strip() if soup.find('div', class_='date') else None\n",
    "        # tags = [tag.text.strip() for tag in soup.find_all('a', class_='app_tag')]\n",
    "        # reviews_url = f\"{url}/reviews/\"\n",
    "        # specs = soup.find('div', class_='game_area_sys_req').text.strip() if soup.find('div', class_='game_area_sys_req') else None\n",
    "        price_elem = soup.find('div', class_='game_purchase_price')\n",
    "        price = price_elem.text.strip() if price_elem else \"Free to Play\"\n",
    "        # early_access = 'Early Access' in soup.find('div', class_='release_date').text if soup.find('div', class_='release_date') else False\n",
    "        # developer_elem = publisher_elem[0].text.strip() if publisher_elem else None\n",
    "        # developer = developer_elem\n",
    "\n",
    "        game_info = {\n",
    "            'publisher': publisher,\n",
    "            'genres': genres,\n",
    "            'app_name': app_name,\n",
    "            # 'title': title,\n",
    "            'release_date': release_date,\n",
    "            # 'tags': tags,\n",
    "            # 'reviews_url': reviews_url,\n",
    "            # 'specs': specs,\n",
    "             'price': price\n",
    "            # 'early_access': early_access,\n",
    "            # 'developer': developer\n",
    "        }\n",
    "        \n",
    "        return game_info\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while scraping URL {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Supongamos que tu dataframe se llama df_steam_games y tiene una columna 'url'\n",
    "def add_game_info_to_df(df):\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        game_info = scrape_steam_game_info(row['url'])\n",
    "        \n",
    "        \n",
    "        if game_info:\n",
    "            # Asignar los valores obtenidos a las columnas correspondientes\n",
    "            df.at[index, 'publisher_scraped'] = game_info['publisher']\n",
    "            df.at[index, 'genres_scraped'] = game_info['genres']\n",
    "            df.at[index, 'app_name_scraped'] = game_info['app_name']\n",
    "        #     df.at[index, 'title'] = game_info['title']\n",
    "            df.at[index, 'release_date_scraped'] = game_info['release_date']\n",
    "        #     df.at[index, 'tags'] = game_info['tags']\n",
    "        #     df.at[index, 'reviews_url'] = game_info['reviews_url']\n",
    "        #     df.at[index, 'specs'] = game_info['specs']\n",
    "            df.at[index, 'price_scraped'] = game_info['price']\n",
    "        #     df.at[index, 'early_access'] = game_info['early_access']\n",
    "        #     df.at[index, 'developer'] = game_info['developer']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Ejecutar la función para añadir la información al dataframe\n",
    "\n",
    "   \n",
    "\n",
    "df_steam_games = add_game_info_to_df(df_steam_games) #iloc[0:1]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
