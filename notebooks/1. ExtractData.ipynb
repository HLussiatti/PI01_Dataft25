{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de Librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga del archivo en un DataFrame: steam_games.json.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo de Steam Games.\n",
    "file_path = r'.\\\\Dataset\\\\steam_games.json.gz'\n",
    "\n",
    "# Lista para almacenar los objetos JSON.\n",
    "data_list = []  \n",
    "\n",
    "# Se abre el archivo con la librería gzip sin necesidad de descomprimirlo previamente.\n",
    "with gzip.open(file_path) as file:\n",
    "    # Se recorre cada línea del arhivo.\n",
    "    for line in file:\n",
    "        # Cargar cada línea como objeto JSON y se agrega a la lista.\n",
    "        data = json.loads(line.decode('utf-8'))  # Decodificado en UTF-8\n",
    "        data_list.append(data)\n",
    "\n",
    "# Convertir la lista de diccionarios en un DataFrame de pandas.\n",
    "df_steam_games = pd.DataFrame(data_list)\n",
    "\n",
    "# Cambiar la columna 'price' a tipo string porque contiene \"Free to Play\" y sino no puedo guardarlo como \"parquet\".\n",
    "df_steam_games['price'] = df_steam_games['price'].astype(str)\n",
    "\n",
    "# Guardo el DF en parquet para levantarlo más rápido la próxima vez.\n",
    "df_steam_games.to_parquet('.\\\\Dataset\\\\steam_games.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga y desanidado del archivo: user_reviews.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo de Reviews.\n",
    "file_path = r'.\\\\Dataset\\\\user_reviews.json.gz'\n",
    "\n",
    "# Lista para almacenar los datos de las reviews.\n",
    "reviews_list = []\n",
    "\n",
    "# Se abre el archivo con la librería gzip sin necesidad de descomprimirlo previamente.\n",
    "with gzip.open(file_path) as file:\n",
    "    \n",
    "    # Se recorre línea por línea ya que cada línea es un objeto\n",
    "    for line in file:\n",
    "\n",
    "        # Se convierte cada línea en un diccionario.\n",
    "        data = ast.literal_eval(line.decode('utf-8'))\n",
    "\n",
    "        # Si el campo \"reviews\" está vacío, se agrega un diccionario con valores None.\n",
    "        if not data['reviews']:\n",
    "            reviews_list.append({\n",
    "                'item_id': None,\n",
    "                'posted': None,\n",
    "                'helpful': None,\n",
    "                'recommend': None,\n",
    "                'funny': None,\n",
    "                'review': None,\n",
    "                'user_id': data['user_id'],\n",
    "                'user_url': data['user_url']\n",
    "            })\n",
    "        else:\n",
    "            # Si el campo \"reviews\" tiene datos, se añade cada reseña al diccionario de resultados con sus respectivos user_id y user_url\n",
    "            for review in data['reviews']:\n",
    "                review['user_id'] = data['user_id']\n",
    "                review['user_url'] = data['user_url']\n",
    "                reviews_list.append(review)\n",
    "\n",
    "# Creo el DataFrame a partir de la lista de diccionarios.\n",
    "df_reviews = pd.DataFrame(reviews_list)\n",
    "\n",
    "# Reorganizo columnas según el orden deseado\n",
    "df_reviews = df_reviews[['user_id', 'user_url', 'item_id', 'posted', 'helpful', 'recommend', 'funny', 'review']]\n",
    "\n",
    "# Guardo el DF en parquet para levantarlo más rápido la próxima vez.\n",
    "df_reviews.to_parquet('.\\\\Dataset\\\\user_reviews.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga y desanidado del archivo: users_items.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo de Reviews.\n",
    "file_path = r'.\\\\Dataset\\\\users_items.json.gz'\n",
    "\n",
    "# Lista para almacenar los datos de las reseñas.\n",
    "items_list = []\n",
    "\n",
    "# Se abre el archivo con la librería gzip sin necesidad de descomprimirlo previamente.\n",
    "with gzip.open(file_path) as file:\n",
    "    \n",
    "    # Se recorre línea por línea ya que cada línea es un objeto\n",
    "    for line in file:\n",
    "\n",
    "        # Se convierte cada línea en un diccionario.\n",
    "        data = ast.literal_eval(line.decode('utf-8'))\n",
    "\n",
    "        # Si el campo \"items\" está vacío, se agrega un diccionario con valores None.\n",
    "        if not data['items']:\n",
    "            items_list.append({\n",
    "                'item_id': None,\n",
    "                'item_name': None,\n",
    "                'playtime_forever': None,\n",
    "                'playtime_2weeks': None,\n",
    "                'user_id': data['user_id'],\n",
    "                'user_url': data['user_url']\n",
    "            })\n",
    "        else:\n",
    "            # Si el campo \"items\" tiene datos, se añade cada reseña al diccionario de resultados con sus respectivos user_id y user_url\n",
    "            for item in data['items']:\n",
    "                item['user_id'] = data['user_id']\n",
    "                item['user_url'] = data['user_url']\n",
    "                items_list.append(item)\n",
    "\n",
    "# Creo el DataFrame a partir de la lista de diccionarios.\n",
    "df_items = pd.DataFrame(items_list)\n",
    "\n",
    "# Reorganizo columnas según el orden deseado\n",
    "df_items = df_items[['user_id', 'user_url', 'item_id', 'item_name', 'playtime_forever', 'playtime_2weeks']]\n",
    "\n",
    "# Guardo el DF en parquet para levantarlo más rápido la próxima vez.\n",
    "df_items.to_parquet('.\\\\Dataset\\\\users_items.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
